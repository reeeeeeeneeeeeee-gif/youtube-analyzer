import streamlit as st
import pandas as pd
from googleapiclient.discovery import build
from datetime import datetime, timezone, timedelta
import io
import re

# --- ì„¤ì •ê°’ ---
SEARCH_PERIOD_DAYS = 90 # ì¸ê¸° ë™ì˜ìƒ ê²€ìƒ‰ ê¸°ê°„ (ì¼)

# --- ê³µí†µ í•¨ìˆ˜: ìœ íŠœë¸Œ ì˜ìƒ ê¸¸ì´(ISO 8601)ë¥¼ ì´ˆ ë‹¨ìœ„ë¡œ ë³€í™˜ ---
def parse_iso8601_duration(duration):
    match = re.match(r'PT(?:(\d+)H)?(?:(\d+)M)?(?:(\d+)S)?', duration).groups()
    hours = int(match[0]) if match[0] else 0
    minutes = int(match[1]) if match[1] else 0
    seconds = int(match[2]) if match[2] else 0
    return hours * 3600 + minutes * 60 + seconds

# --- API í˜¸ì¶œ í•¨ìˆ˜: ìœ íŠœë¸Œ ì¹´í…Œê³ ë¦¬ ëª©ë¡ ê°€ì ¸ì˜¤ê¸° ---
@st.cache_data
def get_video_categories(_youtube, region_code='KR'):
    request = _youtube.videoCategories().list(part="snippet", regionCode=region_code, hl='ko')
    response = request.execute()
    return {item['id']: item['snippet']['title'] for item in response['items']}

# --- ê³µí†µ í•¨ìˆ˜: API ì‘ë‹µ ê²°ê³¼ë¥¼ ë°ì´í„°í”„ë ˆì„ìœ¼ë¡œ ë³€í™˜ ---
def process_video_items(items, category_map):
    video_data = []
    now_utc = datetime.now(timezone.utc)
    for item in items:
        stats = item.get('statistics', {})
        view_count = int(stats.get('viewCount', 0))
        like_count = int(stats.get('likeCount', 0))
        comment_count = int(stats.get('commentCount', 0))
        engagement_rate = (like_count / view_count) * 100 if view_count > 0 else 0
        video_url = f"https://www.youtube.com/watch?v={item['id']}"
        published_at_str = item['snippet']['publishedAt']
        published_at_dt = datetime.fromisoformat(published_at_str.replace('Z', '+00:00'))
        time_since_published = now_utc - published_at_dt
        hours_since_published = max(1, time_since_published.total_seconds() / 3600)
        views_per_hour = int(view_count / hours_since_published)
        upload_date_display = published_at_dt.strftime('%Y-%m-%d')
        duration_iso = item['contentDetails']['duration']
        duration_seconds = parse_iso8601_duration(duration_iso)
        video_type = "ìˆí¼ (Shorts)" if duration_seconds <= 60 else "ë¡±í¼ (Long-form)"
        category_id = item['snippet'].get('categoryId', '')
        category_name = category_map.get(category_id, "ê¸°íƒ€")
        video_data.append({
            'ì œëª©': item['snippet']['title'], 'ì¡°íšŒìˆ˜': view_count, 'ì‹œê°„ë‹¹ ì¡°íšŒìˆ˜': views_per_hour,
            'ì¢‹ì•„ìš” ìˆ˜': like_count, 'ëŒ“ê¸€ ìˆ˜': comment_count, 'ë°˜ì‘ë¥  (%)': engagement_rate,
            'ê²Œì‹œì¼': upload_date_display, 'ì±„ë„ëª…': item['snippet']['channelTitle'],
            'ì¹´í…Œê³ ë¦¬': category_name, 'ì˜ìƒ ì¢…ë¥˜': video_type, 'URL': video_url
        })
    df = pd.DataFrame(video_data)
    column_order = [
        'ì œëª©', 'ì¡°íšŒìˆ˜', 'ì‹œê°„ë‹¹ ì¡°íšŒìˆ˜', 'ì¢‹ì•„ìš” ìˆ˜', 'ëŒ“ê¸€ ìˆ˜', 'ë°˜ì‘ë¥  (%)',
        'ê²Œì‹œì¼', 'ì±„ë„ëª…', 'ì¹´í…Œê³ ë¦¬', 'ì˜ìƒ ì¢…ë¥˜', 'URL'
    ]
    return df[column_order]

# --- API í˜¸ì¶œ í•¨ìˆ˜ 1: í‚¤ì›Œë“œ ê²€ìƒ‰ ---
def get_youtube_data(youtube, category_map, query, max_results=50):
    try:
        # â–¼â–¼â–¼ [ìˆ˜ì •ëœ ë¶€ë¶„] regionCode='KR'ì„ ì¶”ê°€í•˜ì—¬ í•œêµ­ ì˜ìƒìœ¼ë¡œ ì œí•œí•©ë‹ˆë‹¤. â–¼â–¼â–¼
        search_request = youtube.search().list(
            q=query, part='id', type='video', 
            maxResults=max_results, order='relevance', regionCode='KR'
        )
        search_response = search_request.execute()
        video_ids = [item['id']['videoId'] for item in search_response.get('items', [])]
        if not video_ids: return None
        video_request = youtube.videos().list(part="snippet,statistics,contentDetails", id=','.join(video_ids))
        video_response = video_request.execute()
        df = process_video_items(video_response.get('items', []), category_map)
        return df.sort_values(by='ì¡°íšŒìˆ˜', ascending=False)
    except Exception as e:
        st.error(f"ê²€ìƒ‰ ì¤‘ ì˜¤ë¥˜: {e}")
        return None

# --- API í˜¸ì¶œ í•¨ìˆ˜ 2: ì¹´í…Œê³ ë¦¬ë³„ ì¢…í•© ì¸ê¸° ë™ì˜ìƒ ---
@st.cache_data
def get_comprehensive_popular_videos(_youtube, category_map):
    try:
        excluded_categories = ['ìŒì•…', 'ê²Œì„']
        excluded_ids = [cat_id for cat_id, cat_name in category_map.items() if cat_name in excluded_categories]
        all_video_ids = set()
        start_date = (datetime.now(timezone.utc) - timedelta(days=SEARCH_PERIOD_DAYS)).strftime('%Y-%m-%dT%H:%M:%SZ')
        for cat_id, cat_name in category_map.items():
            if cat_id in excluded_ids: continue
            search_request = _youtube.search().list(
                part='id', type='video', videoCategoryId=cat_id,
                maxResults=15, order='viewCount', regionCode='KR',
                publishedAfter=start_date
            )
            search_response = search_request.execute()
            for item in search_response.get('items', []):
                all_video_ids.add(item['id']['videoId'])
        if not all_video_ids: return None
        video_ids_list = list(all_video_ids)
        video_request = _youtube.videos().list(
            part="snippet,statistics,contentDetails",
            id=','.join(video_ids_list)
        )
        video_response = video_request.execute()
        df = process_video_items(video_response.get('items', []), category_map)
        return df.sort_values(by='ì¡°íšŒìˆ˜', ascending=False).head(100)
    except Exception as e:
        st.error(f"ì¹´í…Œê³ ë¦¬ë³„ ì¸ê¸° ë™ì˜ìƒ ë¡œë”© ì¤‘ ì˜¤ë¥˜: {e}")
        return None

# --- Streamlit ì›¹ UI êµ¬ì„± ---
st.set_page_config(page_title="ğŸ“ˆ ìœ íŠœë¸Œ ì˜ìƒ ë¶„ì„ê¸°", page_icon="ğŸ“ˆ", layout="wide")
st.title("ğŸ“ˆ ìœ íŠœë¸Œ ì¸ê¸° ì˜ìƒ ë¶„ì„ê¸°"); st.markdown("---")
try: api_key = st.secrets["YOUTUBE_API_KEY"]
except KeyError: st.error("ğŸ”‘ Streamlit Secretsì— API í‚¤ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. ì•± ì„¤ì •(Manage app)ì—ì„œ ì¶”ê°€í•´ì£¼ì„¸ìš”."); st.stop()
youtube = build('youtube', 'v3', developerKey=api_key); category_map = get_video_categories(youtube)
if 'comprehensive_data' not in st.session_state:
    st.session_state.comprehensive_data = get_comprehensive_popular_videos(youtube, category_map)
st.header("1. í‚¤ì›Œë“œ ê²€ìƒ‰ ë¶„ì„")
with st.form(key="search_form"):
    search_query = st.text_input("ê²€ìƒ‰ì–´ ì…ë ¥ì°½", placeholder="ğŸ” ë¶„ì„í•˜ê³  ì‹¶ì€ ê²€ìƒ‰ì–´ë¥¼ ì…ë ¥í•˜ì„¸ìš”.", label_visibility="collapsed")
    submit_button = st.form_submit_button(label="ğŸ“Š ë¶„ì„ ì‹œì‘!")
if submit_button and search_query:
    with st.spinner('ë°ì´í„°ë¥¼ ê°€ì ¸ì˜¤ëŠ” ì¤‘ì…ë‹ˆë‹¤...'): df_results = get_youtube_data(youtube, category_map, search_query)
    if df_results is not None and not df_results.empty:
        output = io.BytesIO()
        with pd.ExcelWriter(output, engine='openpyxl') as writer: df_results.to_excel(writer, index=False, sheet_name='Sheet1')
        excel_data = output.getvalue()
        col1, col2 = st.columns([0.8, 0.2])
        with col1: st.header("ë¶„ì„ ê²°ê³¼")
        with col2: st.download_button(label="ğŸ“ ì—‘ì…€ íŒŒì¼ ë‹¤ìš´ë¡œë“œ", data=excel_data, file_name=f"youtube_analysis_{search_query}.xlsx", mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet")
        st.dataframe(df_results, height=800, column_config={"ì¡°íšŒìˆ˜": st.column_config.NumberColumn(format="%d"), "ì‹œê°„ë‹¹ ì¡°íšŒìˆ˜": st.column_config.NumberColumn(format="%d"),"ì¢‹ì•„ìš” ìˆ˜": st.column_config.NumberColumn(format="%d"), "ëŒ“ê¸€ ìˆ˜": st.column_config.NumberColumn(format="%d"),"ë°˜ì‘ë¥  (%)": st.column_config.NumberColumn(format="%.2f%%"), "URL": st.column_config.LinkColumn("ì˜ìƒ ë§í¬", display_text="ë°”ë¡œê°€ê¸° â†—")})
    else: st.warning(f"'{search_query}'ì— ëŒ€í•œ ê²€ìƒ‰ ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤.")
st.markdown("---");
st.header(f"2. ì¹´í…Œê³ ë¦¬ë³„ ì¢…í•© ì¸ê¸° ë™ì˜ìƒ (ìµœê·¼ {SEARCH_PERIOD_DAYS}ì¼, TOP 100)")
df_popular = st.session_state.comprehensive_data
if df_popular is not None:
    all_categories = sorted(df_popular['ì¹´í…Œê³ ë¦¬'].unique())
    all_categories.insert(0, "ì „ì²´")
    selected_category = st.selectbox('ğŸ—‚ï¸ í‘œì‹œí•  ì¹´í…Œê³ ë¦¬ë¥¼ ì„ íƒí•˜ì„¸ìš”:', all_categories)
    if selected_category == "ì „ì²´": display_df = df_popular
    else: display_df = df_popular[df_popular['ì¹´í…Œê³ ë¦¬'] == selected_category]
    st.dataframe(display_df, height=800, column_config={"ì¡°íšŒìˆ˜": st.column_config.NumberColumn(format="%d"), "ì‹œê°„ë‹¹ ì¡°íšŒìˆ˜": st.column_config.NumberColumn(format="%d"),"ì¢‹ì•„ìš” ìˆ˜": st.column_config.NumberColumn(format="%d"), "ëŒ“ê¸€ ìˆ˜": st.column_config.NumberColumn(format="%d"),"ë°˜ì‘ë¥  (%)": st.column_config.NumberColumn(format="%.2f%%"), "URL": st.column_config.LinkColumn("ì˜ìƒ ë§í¬", display_text="ë°”ë¡œê°€ê¸° â†—")})
